{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fabiocastilhoss/StepAnalyzerPAT2Math/blob/main/v5_step_analyser_pat2math.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivldMFWiitY7"
      },
      "source": [
        "# Step Analyser PAT2Math - Versão 5"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*   Versão 5\n",
        "*   Transformers\n",
        "*   ~ 80 mil instâncias"
      ],
      "metadata": {
        "id": "jq-ZySLry22I"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDj-ylxdkHAI"
      },
      "source": [
        "Instalação de pacotes e importações"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X0ePfIAuM6ZG"
      },
      "outputs": [],
      "source": [
        "pip install accelerate -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AY3O0bnM7MV"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wjhFIbLPR8W8"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf #Manipulação de expressões matemáticas sobre tensores numéricos\n",
        "from tensorflow import keras #Biblioteca para Deep Learning\n",
        "from keras import layers #Estruturas de dados para Deep Learning\n",
        "from keras.preprocessing.sequence import pad_sequences #Pacote para preenchimento de sequências\n",
        "from keras import activations, optimizers, losses #Módulos para ativação, otimizadores e funções de loss\n",
        "from keras.callbacks import ModelCheckpoint #pacote para salvar o melhor modelo\n",
        "import matplotlib.pyplot as plt #Biblioteca para visualização de dados\n",
        "import seaborn as sns #Biblioteca para visualização de dados\n",
        "import numpy as np #Operações em arrays multidimensionais\n",
        "import pandas as pd #Biblioteca para análise e manipulação de dados\n",
        "import random #Geração de números aleatórios\n",
        "import string #Operações em Strings\n",
        "import re #Operações em expressões regulares\n",
        "from transformers import DistilBertTokenizerFast, TFDistilBertForSequenceClassification #Classes para tokenização, codificação e classificação\n",
        "from sklearn.model_selection import train_test_split #Divisão de conjuntos\n",
        "from sklearn.metrics import confusion_matrix #Matriz de confusão\n",
        "from sklearn.utils import shuffle #Embaralhamento\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score #Importa F1, Precision e Recall\n",
        "from sklearn.metrics import roc_curve, auc #Importa curva ROC\n",
        "from google.colab import drive #Conexão do Google Colab ao Google Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leitura e filtragem do log das interações dos estudantes no PAT2Math."
      ],
      "metadata": {
        "id": "ZcX6-spOUujm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKZkVxJvFDXt"
      },
      "outputs": [],
      "source": [
        "#Conexão com o Google Drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VGQmzhgGTlOj"
      },
      "outputs": [],
      "source": [
        "#Leitura do log de interações do PAT2Math, armazenado no Google Drive\n",
        "log = pd.read_csv(\"/content/drive/MyDrive/colab/fabio-mestrado/log_with_current_step_pat2math.csv\", sep=\",\", encoding=\"latin-1\")\n",
        "log.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g06M9oCKflex"
      },
      "outputs": [],
      "source": [
        "#Filtragem do log para quatro colunas\n",
        "log = log[[\"initial_equation\", \"last_correct_step\", \"currentStep\", \"step_is_correct\"]]\n",
        "log.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "erN77Eha9up6"
      },
      "outputs": [],
      "source": [
        "# Verifica a quatidade de dados faltantes em cada coluna\n",
        "dados_faltantes = log.isna().sum()\n",
        "print(dados_faltantes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-DN-2on_G3x"
      },
      "source": [
        "# Junção de colunas:\n",
        "Para ampliação do conjunto de dados, quando a coluna last_correct_step é diferente de initial_equation, ela é usada como equação inicial, ou seja, uma nova instância é criada, contendo os dados de last_correct_step na coluna initial_equation, mantendo os dados de currentStep e step_is_correct, nas suas colunas equivalentes.\n",
        "\n",
        "No final do procedimento, a coluna last_correct_step é excluída."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQ5E3Xwb9zu0"
      },
      "outputs": [],
      "source": [
        "#Amplia o número de instâncias, inserindo last_correct_step como initial_equation, quando contiverem valores diferentes.\n",
        "\n",
        "# Criar uma lista para armazenar os novos dados\n",
        "new_rows = []\n",
        "\n",
        "# Iterar sobre cada linha do DataFrame\n",
        "for index, row in log.iterrows():\n",
        "    if row['initial_equation'] != row['last_correct_step']:\n",
        "        new_row = row.copy()  # Copiar a linha existente\n",
        "        new_row['initial_equation'] = row['last_correct_step']  # Atualizar 'initial_equation'\n",
        "        new_rows.append(new_row)  # Adicionar a nova linha à lista\n",
        "\n",
        "# Adicionar as novas linhas ao DataFrame\n",
        "log = log.append(new_rows, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-bQrPlVa9-NE"
      },
      "outputs": [],
      "source": [
        "#Filtra o log resultante para apenas três colunas\n",
        "log = log[[\"initial_equation\", \"currentStep\", \"step_is_correct\"]]\n",
        "log"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiADD1Ji_5WC"
      },
      "source": [
        "A junção de colunas resulta em 251.777 instâncias."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tratamento de Dados:\n",
        "\n",
        "*   Retiradas de duplicatas\n",
        "*   Retirada de dados faltantes\n",
        "*   Verificação de caracteres inválidos\n",
        "*   Padronização da equação\n",
        "*   Checagem e correção dos rótulos"
      ],
      "metadata": {
        "id": "oGnbJC00VhpG"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEfMHfw2AK4a"
      },
      "source": [
        "## Retira duplicatas\n",
        "\n",
        "Exclui instâncias que contém dados duplicados, usando como chave as duas colunas: initial_equation e currentStep. Só exclui quando ambas contiverem valores iguais, reduzindo o número de instâncias para 34.769."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aek1yBd8AM2S"
      },
      "outputs": [],
      "source": [
        "#Exclui instâncias duplicadas\n",
        "log = log.drop_duplicates(subset=['initial_equation', 'currentStep'])\n",
        "log.head(), log.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4AvvU0uAXos"
      },
      "source": [
        "## Retira linhas com valores faltantes\n",
        "\n",
        "Exclui as instâncias que contém valores faltantes, reduzindo o número de instâncias para 30.279."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FTDhjc9IAW8c"
      },
      "outputs": [],
      "source": [
        "#Exclui as instâncias que contém valores faltantes\n",
        "log = log.dropna()\n",
        "log.head(), log.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifica o número de rótulos corretos e incorretos"
      ],
      "metadata": {
        "id": "z8vYV1SPV6Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Conta número de instâncias com label incorreto e correto\n",
        "counts = log[\"step_is_correct\"].value_counts()\n",
        "counts"
      ],
      "metadata": {
        "id": "qjZcg-pSV9Ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crie um gráfico de barras\n",
        "plt.bar(counts.index, counts.values, color=['red', 'blue'], edgecolor='k')\n",
        "\n",
        "# Adicione rótulos e título\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Instâncias\")\n",
        "plt.title(\"Contagem de Instâncias com Rótulo Incorreto e Correto\")\n",
        "\n",
        "# Personalize os rótulos no eixo x (opcional)\n",
        "plt.xticks(counts.index, ['Incorreto', 'Correto'])\n",
        "\n",
        "# Mostre o gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "B56FS2raWAtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGNUtNt5SMfE"
      },
      "source": [
        "# Pré-Processamento\n",
        "\n",
        "*    Balanceamento de Dados - Data Augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Balanceamento de Dados\n",
        "\n",
        "O balanceamento de dados é realizado através da função data augmentation.\n",
        "\n",
        "*    A função de data augmentation (augment_equation) recebe uma equação da coluna initial equation e o indicador correct (para gerar uma equação correta ou incorreta). Essa função, quando correct é informado como 1, insere operações aleatórias de adição, subtração, multiplicação e divisão dos dois lados da equação. No final, também aleatoriamente, pode inverter os lados da equação. Se correct é 0, a inserção é realizada em apenas um lado da equação, tornando-a incorreta."
      ],
      "metadata": {
        "id": "FngCj8d9WMJY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3Hh0uqvSYFu"
      },
      "outputs": [],
      "source": [
        "# Função de data augmentation para alterar initial equation, incluindo instâncias corretas ou incorretas\n",
        "def augment_equation(equation, correct):\n",
        "\n",
        "    # Separa os lados da equação e retira os espaços em branco\n",
        "    left, right = equation.split('=')\n",
        "    left = left.strip()\n",
        "    right = right.strip()\n",
        "\n",
        "    # Seleciona aleatoriamente uma ou duas operações\n",
        "    choice = random.choice([\"add\", \"multiply\", \"div\", \"add&multiply\", \"add&div\"])\n",
        "\n",
        "    # Gera constantes aleatórias entre -100 e 100 (inclusive)\n",
        "    constant_to_add = random.randint(-100, 100)\n",
        "    constant_to_multiply = random.choice([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10])\n",
        "    constant_to_div = random.choice([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, -1, -2, -3, -4, -5, -6, -7, -8, -9, -10])\n",
        "\n",
        "    # Se correct == 1, adiciona as operações a ambos os lados\n",
        "    if correct:\n",
        "      # Adição\n",
        "      if choice in [\"add\", \"add&multiply\", \"add&div\"]:\n",
        "        if constant_to_add >= 0:\n",
        "          left = f\"({left}) + {constant_to_add}\"\n",
        "          right = f\"({right}) + {constant_to_add}\"\n",
        "        else:\n",
        "          left = f\"({left}) + ({constant_to_add})\"\n",
        "          right = f\"({right}) + ({constant_to_add})\"\n",
        "\n",
        "      # Multiplicação\n",
        "      if choice in [\"multiply\", \"add&multiply\"]:\n",
        "        if constant_to_multiply >= 0:\n",
        "          left = f\"({left}) * {constant_to_multiply}\"\n",
        "          right = f\"({right}) * {constant_to_multiply}\"\n",
        "        else:\n",
        "          left = f\"({left}) * ({constant_to_multiply})\"\n",
        "          right = f\"({right}) * ({constant_to_multiply})\"\n",
        "\n",
        "      # Divisão\n",
        "      if choice in [\"div\", \"add&div\"]:\n",
        "        if constant_to_div >= 0:\n",
        "          left = f\"({left}) / {constant_to_div}\"\n",
        "          right = f\"({right}) / {constant_to_div}\"\n",
        "        else:\n",
        "          left = f\"({left}) / ({constant_to_div})\"\n",
        "          right = f\"({right}) / ({constant_to_div})\"\n",
        "\n",
        "    # Se correct == 0, adiciona as operações apenas no lado esquerdo\n",
        "    else:\n",
        "\n",
        "      # Adição\n",
        "      if choice in [\"add\", \"add&multiply\", \"add&div\"]:\n",
        "        if constant_to_add >= 0:\n",
        "          left = f\"({left}) + {constant_to_add}\"\n",
        "        else:\n",
        "          left = f\"({left}) + ({constant_to_add})\"\n",
        "\n",
        "      # Multiplicação\n",
        "      if choice in [\"multiply\", \"add&multiply\"]:\n",
        "        if constant_to_multiply >= 0:\n",
        "          left = f\"({left}) * {constant_to_multiply}\"\n",
        "        else:\n",
        "          left = f\"({left}) * ({constant_to_multiply})\"\n",
        "\n",
        "      # Divisão\n",
        "      if choice in [\"div\", \"add&div\"]:\n",
        "        if constant_to_div >= 0:\n",
        "          left = f\"({left}) / {constant_to_div}\"\n",
        "        else:\n",
        "          left = f\"({left}) / ({constant_to_div})\"\n",
        "\n",
        "    # Troca os lados da equação aleatoriamente\n",
        "    if random.choice([True, False]):\n",
        "        left, right = right, left\n",
        "\n",
        "    # Retira espaços em branco e retorna equação initial equation modificada\n",
        "    left = left.replace(\" \", \"\")\n",
        "    right = right.replace(\" \", \"\")\n",
        "    return f\"{left}={right}\"\n",
        "\n",
        "# Exemplo da equação \"2x + 3 = 5\" correta e incorreta\n",
        "equation = \"2x + 3 = 5\"\n",
        "augmented_equation1 = augment_equation(equation, 1)\n",
        "augmented_equation2 = augment_equation(equation, 0)\n",
        "print(\"Equação Correta: \", augmented_equation1)\n",
        "print(\"Equação Incorreta: \", augmented_equation2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "csYojNorSfpV"
      },
      "outputs": [],
      "source": [
        "# Contar o número de ocorrências de step_is_correct igual a 1 e 0\n",
        "count_correct = log['step_is_correct'].value_counts()[1.0]\n",
        "count_incorrect = log['step_is_correct'].value_counts()[0.0]\n",
        "\n",
        "print(\"Número de linhas com passos corretos:\", count_correct)\n",
        "print(\"Número de linhas com passos incorretos:\", count_incorrect)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljFtFbKZg-xZ"
      },
      "outputs": [],
      "source": [
        "# Variável log_temp recebe rótulos corretos (7.851)\n",
        "log_temp = log[log[\"step_is_correct\"] == 1.0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "O código abaixo aplica 4 vezes a função augment_equation com correct == 1, nos rótulos corretos, aumentando de 7.851 instâncias corretas para 39.255.\n",
        "\n",
        "Após, ele aplica 2 vezes a função augment_equation com correct == 0, nos rótulos corretos, aumentando os rótulos incorretos de 22.428 para 38.130."
      ],
      "metadata": {
        "id": "xnu7WrwLXtXI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHNFiDuzhDrt"
      },
      "outputs": [],
      "source": [
        "# Lista de rótulos para as funções\n",
        "labels = [1.0, 1.0, 1.0, 1.0, 0.0, 0.0]\n",
        "\n",
        "# Lista para armazenar os DataFrames gerados\n",
        "new_dataframes = []\n",
        "\n",
        "# Aplica função augment_equation 5 vezes para geração de equações corretas e 3 para geração de equações incorretas\n",
        "# Loop para aplicar as funções e criar os DataFrames\n",
        "for i, lab in enumerate(labels):\n",
        "    new_rows = log_temp.apply(lambda row: pd.Series({'initial_equation': augment_equation(row['initial_equation'], int(labels[i])),\n",
        "                                                     'currentStep': row['currentStep'],\n",
        "                                                     'step_is_correct': labels[i]}), axis=1)\n",
        "    # Anexar as novas linhas ao DataFrame original\n",
        "    log = log.append(new_rows, ignore_index=True)\n",
        "\n",
        "# Imprime o log atualizado\n",
        "log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVoiRhulhJWL"
      },
      "outputs": [],
      "source": [
        "# Contar o número de ocorrências de step_is_correct igual a 1 e 0\n",
        "count_correct = log['step_is_correct'].value_counts()[1.0]\n",
        "count_incorrect = log['step_is_correct'].value_counts()[0.0]\n",
        "\n",
        "print(\"Número de linhas com passos corretos:\", count_correct)\n",
        "print(\"Número de linhas com passos incorretos:\", count_incorrect)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variável counts recebe os valores de rótulos corretos e incorretos\n",
        "counts = log[\"step_is_correct\"].value_counts()\n",
        "\n",
        "# Crie um gráfico de barras\n",
        "plt.bar(counts.index, counts.values, color=['red', 'blue'], edgecolor='k')\n",
        "\n",
        "# Adicione rótulos e título\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Instâncias\")\n",
        "plt.title(\"Contagem de Instâncias com Rótulo Incorreto e Correto\")\n",
        "\n",
        "# Personalize os rótulos no eixo x (opcional)\n",
        "plt.xticks(counts.index, ['Incorreto', 'Correto'])\n",
        "\n",
        "# Mostre o gráfico\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_YieE3JVYUP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5KzhaIQwSshj"
      },
      "outputs": [],
      "source": [
        "# Exclui os valores duplicados novamente, desde que constem como iguais em ambas as colunas: initial equation e currentStep\n",
        "log = log.drop_duplicates(subset=['initial_equation', 'currentStep'])\n",
        "log.head(), log.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMIG-S7ASv6f"
      },
      "outputs": [],
      "source": [
        "# Contar o número de ocorrências de step_is_correct igual a 1 e 0\n",
        "counts = counts = log[\"step_is_correct\"].value_counts()\n",
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HZp9ntFESy4D"
      },
      "outputs": [],
      "source": [
        "# Crie um gráfico de barras\n",
        "plt.bar(counts.index, counts.values, color=['red', 'blue'], edgecolor='k')\n",
        "\n",
        "# Adicione rótulos e título\n",
        "plt.xlabel(\"Status\")\n",
        "plt.ylabel(\"Instâncias\")\n",
        "plt.title(\"Contagem de Instâncias com Rótulo Incorreto e Correto\")\n",
        "\n",
        "# Personalize os rótulos no eixo x (opcional)\n",
        "plt.xticks(counts.index, ['Incorreto', 'Correto'])\n",
        "\n",
        "# Mostre o gráfico\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprime log atualizado\n",
        "log"
      ],
      "metadata": {
        "id": "eNLxepF1J_k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Converte o tipo da coluna step is correct, de float para inteiro.\n",
        "log['step_is_correct'] = log['step_is_correct'].astype(int)"
      ],
      "metadata": {
        "id": "i5qzhK-EyIlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "log.head()"
      ],
      "metadata": {
        "id": "vGKzFDFqyLBZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embaralhar o conjunto de dados."
      ],
      "metadata": {
        "id": "5qiToRcqYwrZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_N4ccSNL0v51"
      },
      "outputs": [],
      "source": [
        "# Cria variável para embaralhar o conjunto de dados\n",
        "passos_embaralhados = shuffle(log)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MqoGdmzfvvxq"
      },
      "outputs": [],
      "source": [
        "# Embaralha os dados de entrada e os rótulos\n",
        "X_series = passos_embaralhados[['initial_equation', 'currentStep']]\n",
        "y_series = passos_embaralhados['step_is_correct']\n",
        "X = X_series.values.tolist()\n",
        "y = y_series.tolist()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenização e Encoding\n",
        "\n",
        "Baseado em https://colab.research.google.com/github/peterbayerle/huggingface_notebook/blob/main/distilbert_tf.ipynb#scrollTo=fKTJqUF5R-o4\n",
        "\n"
      ],
      "metadata": {
        "id": "3bopgottZFxH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKvjomcytNT1"
      },
      "outputs": [],
      "source": [
        "# Comprimento de cada passo tokenizado\n",
        "MAX_LEN = 20"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ubJQH9WN2kW"
      },
      "outputs": [],
      "source": [
        "# Inicializar o tokenizador e o modelo\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenização dos conjuntos de treinamento e teste\n",
        "encodings = tokenizer(X, truncation=True, padding=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AW3QtMJbuzKn"
      },
      "outputs": [],
      "source": [
        "#Transformando os dados em um dataset tensorflow para otimizar o processamento da rede neural\n",
        "tfdataset = tf.data.Dataset.from_tensor_slices((dict(encodings),y))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Divisão de conjuntos\n",
        "\n",
        "Aqui os dados são divididos em três conjuntos: conjunto de treinamento, com 70% das instâncias, conjunto de validação, com 20% das instâncias e conjunto de testes, com 10% das instâncias. Além disso, o tamanho de lote é definido com 32."
      ],
      "metadata": {
        "id": "FESdWmPuZYyh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TEST_SPLIT = 0.1 # Conjunto de teste com 10% dos passos\n",
        "VAL_SPLIT = 0.2 # Conjunto de validação com 20% dos passos\n",
        "BATCH_SIZE = 32 # Tamanho do lote\n",
        "\n",
        "# Define o tamanho dos três conjuntos de dados\n",
        "train_size = int(len(X) * (1 - (TEST_SPLIT + VAL_SPLIT)))\n",
        "val_size = int(len(X) * VAL_SPLIT)\n",
        "\n",
        "tfdataset_train = tfdataset.take(train_size)\n",
        "remainder = tfdataset.skip(train_size)\n",
        "\n",
        "tfdataset_val = remainder.take(val_size)\n",
        "tfdataset_test = remainder.skip(val_size)\n",
        "\n",
        "# Exibir os tamanhos dos conjuntos de dados resultantes\n",
        "print(\"Tamanho do conjunto de treinamento:\", len(tfdataset_train))\n",
        "print(\"Tamanho do conjunto de validação:\", len(tfdataset_val))\n",
        "print(\"Tamanho do conjunto de teste:\", len(tfdataset_test))\n",
        "\n",
        "tfdataset_train = tfdataset_train.batch(BATCH_SIZE)\n",
        "tfdataset_val = tfdataset_val.batch(BATCH_SIZE)\n",
        "tfdataset_test = tfdataset_test.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "7cVXVArYaRH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eaDDKgFAv0iM"
      },
      "source": [
        "# Treinamento e Validação\n",
        "\n",
        "Aqui o modelo é treinado e validado. O melhor modelo é armazenado na variável 'melhor_modelo'.\n",
        "\n",
        "O treinamento é realizado com 25 épocas, otimizador Adam com learning rate de 3e-5 e função de loss Sparse Categorical Crossentropy. O modelo utiliza o transformer DistilBertforSequence Classsification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "30662CbMyFyI"
      },
      "outputs": [],
      "source": [
        "# Hiperparâmetros configuráveis\n",
        "N_EPOCHS = 25\n",
        "MODEL_NAME = 'distilbert-base-uncased'\n",
        "LEARNING_RATE = 3e-5\n",
        "CHECKPOINT_FILE = 'melhor_modelo'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MB1gAzFkwBJS"
      },
      "outputs": [],
      "source": [
        "# Cria um callback ModelCheckpoint para salvar o melhor modelo com base na perda de validação\n",
        "checkpoint = ModelCheckpoint(CHECKPOINT_FILE, monitor='val_loss', save_best_only=True, save_format='tf')\n",
        "\n",
        "# Carrega o modelo pré-treinado DistilBERT\n",
        "model = TFDistilBertForSequenceClassification.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Define o otimizador, função de perda e métricas\n",
        "optimizer = optimizers.Adam(learning_rate=LEARNING_RATE)\n",
        "loss = losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
        "\n",
        "# Treina o modelo usando model.fit()\n",
        "history = model.fit(tfdataset_train, epochs=N_EPOCHS, batch_size=BATCH_SIZE,\n",
        "                    validation_data=tfdataset_val, callbacks=[checkpoint])\n",
        "\n",
        "# Imprime as métricas de treinamento e validação\n",
        "print(\"Training loss:\", history.history['loss'])\n",
        "print(\"Training accuracy:\", history.history['accuracy'])\n",
        "print(\"Validation loss:\", history.history['val_loss'])\n",
        "print(\"Validation accuracy:\", history.history['val_accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbhTZfW2yz12"
      },
      "source": [
        "# Teste\n",
        "\n",
        "O melhor modelo, de acordo com o menor valor de loss no conjunto de validação, é testado no conjunto de testes, que possui cerca de 11 mil instâncias."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aqwLDuRhzB4D"
      },
      "outputs": [],
      "source": [
        "# Avaliação do modelo no conjunto de testes\n",
        "benchmarks = model.evaluate(tfdataset_test, return_dict=True, batch_size=BATCH_SIZE)\n",
        "print(benchmarks)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Gráficos da evolução da acurácia e da perda nos conjuntos de treinamento e validação."
      ],
      "metadata": {
        "id": "wsgR_0oyZ6j4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotar a curva de aprendizado da perda\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, N_EPOCHS+1), history.history['loss'], 'r', label='Training Loss')\n",
        "plt.plot(range(1, N_EPOCHS+1), history.history['val_loss'], 'b', label='Validation Loss')\n",
        "plt.title('Curva de Aprendizado - Perda')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()\n",
        "\n",
        "# Plotar a curva de aprendizado da acurácia\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(range(1, N_EPOCHS+1), history.history['accuracy'], 'r', label='Training Accuracy')\n",
        "plt.plot(range(1, N_EPOCHS+1), history.history['val_accuracy'], 'b', label='Validation Accuracy')\n",
        "plt.title('Curva de Aprendizado - Acurácia')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Nc2OS_oaIYvq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tabela com a lista de equações de teste, rótulos e probabilidades\n",
        "\n",
        "A tabela abaixo lista todas as equações iniciais e passos atuais do conjunto de testes. Para cada uma, a tabela mostra a probabilidade com que o modelo chegou a uma predição, o rótulo predito, o rótulo real e o resultado (se o modelo acertou ou errou a predição)."
      ],
      "metadata": {
        "id": "E-otRwIoaH8g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Listas para armazenar as previsões, probabilidades e inputs\n",
        "predictions = []\n",
        "probabilities = []\n",
        "inputs_list = []  # Lista para armazenar os IDs de entrada\n",
        "labels_list = []\n",
        "\n",
        "# Função para decodificar mantendo apenas o [SEP]\n",
        "def decode_with_sep(input_ids):\n",
        "    input_text = tokenizer.decode(input_ids)\n",
        "    # Remova todos os tokens especiais, exceto [SEP]\n",
        "    input_text = input_text.replace(\"[CLS]\", \"\").replace(\"[PAD]\", \"\").replace(\"[UNK]\", \"\")\n",
        "    return input_text.strip()\n",
        "\n",
        "# Loop através do conjunto de testes\n",
        "for batch in tfdataset_test:\n",
        "    # Obtém as entradas e os rótulos do lote\n",
        "    inputs, labels = batch\n",
        "\n",
        "    # Realiza a previsão com os tensores de entrada\n",
        "    predictions_batch = model(inputs)\n",
        "\n",
        "    # Obtém as probabilidades das classes\n",
        "    probabilities_batch = tf.nn.softmax(predictions_batch.logits, axis=1)\n",
        "\n",
        "    # Obtém as probabilidades da classe correta (classe 1)\n",
        "    probabilities_correct = probabilities_batch[:, 1].numpy()\n",
        "\n",
        "    # Determina se as previsões estão corretas ou incorretas com base em um limite (por exemplo, 0,5)\n",
        "    is_correct_batch = probabilities_correct > 0.5\n",
        "\n",
        "    # Armazena as previsões e probabilidades deste lote\n",
        "    predictions.extend(is_correct_batch)\n",
        "    probabilities.extend(probabilities_correct)\n",
        "\n",
        "    # Adiciona apenas os IDs de entrada à lista\n",
        "    inputs_list.extend(inputs[\"input_ids\"].numpy())  # Adicione \".numpy()\" para converter o tensor para uma lista\n",
        "\n",
        "    # Adiciona os rótulos à lista de rótulos\n",
        "    labels_list.extend(labels.numpy())  # Adicione \".numpy()\" para converter o tensor para uma lista\n",
        "\n",
        "# Decodifica os IDs de entrada em texto mantendo apenas o [SEP]\n",
        "input_texts = [decode_with_sep(ids) for ids in inputs_list]\n",
        "\n",
        "input_texts1 = []\n",
        "input_texts2 = []\n",
        "\n",
        "for text in input_texts:\n",
        "    try:\n",
        "        # Divida o texto pelo [SEP] no meio e retira os espaços\n",
        "        it1, it2 = text.split(\"[SEP]\", 1)\n",
        "        it2 = it2.replace(\"[SEP]\", \"\")\n",
        "        it1 = it1.rstrip()\n",
        "        it2 = it2.rstrip()\n",
        "        input_texts1.append(it1)\n",
        "        input_texts2.append(it2)\n",
        "    except ValueError:\n",
        "        # Se houver um erro ao dividir, imprime o texto problemático e continue\n",
        "        print(f\"Erro ao dividir o texto: {text}\")\n",
        "\n",
        "# Cria uma lista de resultados com base na comparação entre Previsão e Rótulo\n",
        "resultados = [\"Certo\" if p == r else \"Errado\" for p, r in zip(predictions, labels_list)]\n",
        "\n",
        "# Crie um DataFrame com as previsões, probabilidades e entradas originais\n",
        "data = {\n",
        "    \"Equação Inicial\": input_texts1,  # Use os textos decodificados\n",
        "    \"Passo Atual\": input_texts2,  # Use os textos decodificados\n",
        "    \"Probabilidade (%)\": [p * 100 for p in probabilities],\n",
        "    \"Rótulo Predito\": [1 if p else 0 for p in predictions],\n",
        "    \"Rótulo Verdadeiro\": labels_list,  # Adicione a lista de rótulos\n",
        "    \"Resultado\": resultados  # Adicione a lista de resultados\n",
        "}\n",
        "df = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "_tKgg2BbOZ8U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Imprime o dataframe/tabela\n",
        "df"
      ],
      "metadata": {
        "id": "suUNJQ7va6-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verifica o número de instâncias classificadas corretamente pelo modelo."
      ],
      "metadata": {
        "id": "0CjWbU9qaVWY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Verifica o número de instâncias classificadas corretamente pelo modelo\n",
        "df[\"Resultado\"].value_counts()"
      ],
      "metadata": {
        "id": "gMyudtMYa_ws"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calcula o percentual de acerto do modelo, com base na tabela criada."
      ],
      "metadata": {
        "id": "cKDEJBEdacHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Contagem dos valores \"Certo\" e \"Errado\" na coluna \"Resultado\"\n",
        "contagem_resultados = df[\"Resultado\"].value_counts()\n",
        "\n",
        "# Calcula o percentual de acerto\n",
        "percentual_acerto = (contagem_resultados[\"Certo\"] / len(df)) * 100\n",
        "\n",
        "# Imprime o percentual de acerto\n",
        "print(f\"Percentual de acerto: {percentual_acerto:.2f}%\")"
      ],
      "metadata": {
        "id": "MxzFpOz7bZeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matriz de confusão\n",
        "\n",
        "A matriz de confusão abaixo, lista as instânclas classificadas. Em azul escuro, as instâncias classificadas corretamente. Em azul claro, as instâncias classificadas de forma incorreta."
      ],
      "metadata": {
        "id": "Umfq-Jqaajrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calcular a matriz de confusão\n",
        "cm = confusion_matrix(labels_list, [1 if p else 0 for p in predictions])\n",
        "\n",
        "# Definir rótulos das classes (substitua pelos seus rótulos)\n",
        "class_names = ['Classe 0', 'Classe 1']\n",
        "\n",
        "# Criar um heatmap da matriz de confusão\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.set(font_scale=1.2)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,\n",
        "            xticklabels=class_names, yticklabels=class_names)\n",
        "plt.xlabel('Rótulos Previstos')\n",
        "plt.ylabel('Rótulos Reais')\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v6YmTBHbXoiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Precision, Recall e F1 Score\n",
        "\n",
        "*    Precision = Verdadeiros Positivos(TP) / (Verdadeiros Positivos(TP) + Falsos Positivos(FP))\n",
        "*    Recall = Verdadeiros Positivos(TP) / (Verdadeiros Positivos(TP) + Falsos Negativos(FN))\n",
        "*    F1 Score = 2 * (Precision * Recall) / (Precision + Recall)"
      ],
      "metadata": {
        "id": "yrqv8Hprylw-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exemplo de valores verdadeiros (ground truth) e previsões\n",
        "verdadeiros = labels_list\n",
        "previsoes = [1 if p else 0 for p in predictions]\n",
        "\n",
        "# Calcular a precisão e a revocação\n",
        "precisao = precision_score(verdadeiros, previsoes)\n",
        "revocacao = recall_score(verdadeiros, previsoes)\n",
        "# Calcular o F1 Score\n",
        "f1 = f1_score(verdadeiros, previsoes)\n",
        "\n",
        "print(\"Precisão (Precision):\", precisao)\n",
        "print(\"Revocação (Recall):\", revocacao)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "id": "AjpqRhCyymj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Curva ROC"
      ],
      "metadata": {
        "id": "Z_03O2jUyrfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpr, tpr, thresholds = roc_curve(labels_list, [p * 100 for p in probabilities])\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "# Plote a curva ROC\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, color='darkorange', lw=2, label='Curva ROC (AUC = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('Taxa de Falsos Positivos')\n",
        "plt.ylabel('Taxa de Verdadeiros Positivos')\n",
        "plt.title('Curva ROC')\n",
        "plt.legend(loc='lower right')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "0ostANm3ysQq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}